{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0975c9f4",
   "metadata": {},
   "source": [
    "# üìò MNIST Curve Adjustment Layers (CALs) ‚Äî Experimental Baseline\n",
    "\n",
    "## üß† Overview\n",
    "\n",
    "In this notebook, we establish a **strong and interpretable control model** on the **MNIST handwritten digit classification task**, forming the **foundation for our exploration of Curve Adjustment Layers (CALs)** ‚Äî a novel technique aimed at improving neural network convergence and generalization.\n",
    "\n",
    "CALs act as *intermediary modules* between neural layers, applying **learned deformation curves** to activations. These curves serve to *bend the output space* toward more optimal configurations, enabling the model to adaptively reshape internal representations.\n",
    "\n",
    "This notebook provides:\n",
    "- ‚úÖ A solid CNN-based reference model\n",
    "- üì• MNIST dataset loading and visualization\n",
    "- üß∞ Preliminaries for future CAL insertion and ablation studies\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295b8510",
   "metadata": {},
   "source": [
    "## Install any packages needed ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b17b5f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.3-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.58.0-cp312-cp312-win_amd64.whl.metadata (106 kB)\n",
      "     ---------------------------------------- 0.0/106.6 kB ? eta -:--:--\n",
      "     ------- ----------------------------- 20.5/106.6 kB 682.7 kB/s eta 0:00:01\n",
      "     ----------------------------- --------- 81.9/106.6 kB 1.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- 106.6/106.6 kB 1.2 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\atcar\\source\\playground\\arkaen-ml\\script\\python\\.conda\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\atcar\\source\\playground\\arkaen-ml\\script\\python\\.conda\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\atcar\\source\\playground\\arkaen-ml\\script\\python\\.conda\\lib\\site-packages (from matplotlib) (11.0.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\atcar\\source\\playground\\arkaen-ml\\script\\python\\.conda\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\atcar\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.10.3-cp312-cp312-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/8.1 MB 3.1 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.5/8.1 MB 5.1 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.1/8.1 MB 7.8 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.2/8.1 MB 7.2 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.4/8.1 MB 5.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.1/8.1 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 2.5/8.1 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.4/8.1 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 4.5/8.1 MB 11.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.6/8.1 MB 12.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 6.9/8.1 MB 13.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.0/8.1 MB 14.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 14.3 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.2-cp312-cp312-win_amd64.whl (223 kB)\n",
      "   ---------------------------------------- 0.0/223.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 223.0/223.0 kB ? eta 0:00:00\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.58.0-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 1.1/2.2 MB 23.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 27.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 23.5 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.8-cp312-cp312-win_amd64.whl (71 kB)\n",
      "   ---------------------------------------- 0.0/71.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 71.9/71.9 kB ? eta 0:00:00\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.0 kiwisolver-1.4.8 matplotlib-3.10.3 pyparsing-3.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea013451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd567bf",
   "metadata": {},
   "source": [
    "# Grab the MNIST Dataset:\n",
    "---\n",
    "\n",
    "The MNIST dataset is a collection of 70,000 handwritten digits (0-9) that is commonly used for training various image processing systems.\n",
    "\n",
    "\n",
    "## üìä Dataset Summary: MNIST\n",
    "\n",
    "- **Type**: Grayscale handwritten digits  \n",
    "- **Size**: `60,000` training / `10,000` test samples  \n",
    "- **Resolution**: `28√ó28` pixels  \n",
    "- **Classes**: Digits `0‚Äì9`  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fb29ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST dataset downloaded to: ..\\data\n"
     ]
    }
   ],
   "source": [
    "# Download MNIST dataset to a local directory:\n",
    "# M:\\dev\\ml\\data\n",
    "\n",
    "data_path = os.path.join('..', 'data')\n",
    "mnist_train = datasets.MNIST( data_path, train=True, download=True )\n",
    "mnist_test  = datasets.MNIST( data_path, train=False, download=True )\n",
    "print( \"MNIST dataset downloaded to:\", data_path )\n",
    "\n",
    "count_train = len( mnist_train )\n",
    "count_test = len( mnist_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d08f8aa",
   "metadata": {},
   "source": [
    "# Examine the data:\n",
    "---\n",
    "\n",
    "Read data samples and view the image and label ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b01dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 60000\n",
      "Number of test samples: 10000\n",
      "Image: <PIL.Image.Image image mode=L size=28x28 at 0x1627A6B94C0> Label: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print( \"Number of training samples:\", count_train )\n",
    "print( \"Number of test samples:\", count_test )\n",
    "\n",
    "# Examine data samples:\n",
    "img, label = mnist_train[ torch.randint( 0, count_train, ( ) ) ]\n",
    "print( \"Image:\", img, \"Label:\", label )\n",
    "\n",
    "# Display the first image:\n",
    "img.show( )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee88cd6",
   "metadata": {},
   "source": [
    "## üì¶ Data Loader & Hyperparameter Setup\n",
    "\n",
    "To train our CNN model efficiently, we define a few key **training hyperparameters** and configure a **data preprocessing pipeline** that prepares the MNIST dataset for use in PyTorch.\n",
    "\n",
    "---\n",
    "\n",
    "### üéõÔ∏è Training Hyperparameters\n",
    "\n",
    "| Hyperparameter   | Value      | Description                                                       |\n",
    "|------------------|------------|-------------------------------------------------------------------|\n",
    "| `batch_size`     | `64`       | Number of samples per batch ‚Äî balances speed and gradient quality |\n",
    "| `epochs`         | `5`        | Total passes over the training set                               |\n",
    "| `lr`             | `0.001`    | Learning rate ‚Äî controls optimizer step size                      |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507d18e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "lr = 0.001\n",
    "\n",
    "# Create the transform function to convert the image to a tensor and normalize it:\n",
    "# (Note: The normalization values are based on the MNIST dataset statistics.)\n",
    "transforms = transforms.Compose( [\n",
    "    transforms.ToTensor( ),\n",
    "    transforms.Normalize( ( 0.1307, ), ( 0.3081, ) ),\n",
    "] )\n",
    "\n",
    "# Create a DataLoader to load the dataset in batches:\n",
    "data_loader = DataLoader( mnist_train,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          transform=transforms )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0624fe45",
   "metadata": {},
   "source": [
    "# üß† MNIST Control Model Architecture Overview\n",
    "\n",
    "## üéØ Objective\n",
    "\n",
    "This notebook establishes a **well-performing, yet minimal and interpretable convolutional neural network (CNN)** designed to solve the **MNIST handwritten digit classification problem**. Our intent is to create a **robust \"control\" architecture** for later comparative experiments involving more advanced or experimental models. MNIST is a widely used benchmark dataset for evaluating model performance in image recognition tasks.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## üß± Model Architecture\n",
    "\n",
    "A lightweight yet competitive CNN inspired by classical deep learning pipelines.\n",
    "\n",
    "| Layer              | Type            | Shape In ‚Üí Out      | Activation | Notes                         |\n",
    "|--------------------|------------------|----------------------|------------|-------------------------------|\n",
    "| üîπ Input           | Image            | `1 √ó 28 √ó 28`        | ‚Äì          | Grayscale digit image         |\n",
    "| üî∏ Conv1           | Conv2d(1‚Üí32, 3√ó3) | `28 √ó 28 ‚Üí 28 √ó 28`  | ReLU       | Padding preserves resolution  |\n",
    "| üî∏ MaxPool1        | MaxPool2d(2√ó2)   | `28 √ó 28 ‚Üí 14 √ó 14`  | ‚Äì          | Downsamples feature maps      |\n",
    "| üî∏ Conv2           | Conv2d(32‚Üí64, 3√ó3)| `14 √ó 14 ‚Üí 14 √ó 14` | ReLU       | Captures mid-level patterns   |\n",
    "| üî∏ MaxPool2        | MaxPool2d(2√ó2)   | `14 √ó 14 ‚Üí 7 √ó 7`    | ‚Äì          | Further spatial reduction     |\n",
    "| üî∏ Flatten         | ‚Äì                | `64 √ó 7 √ó 7 ‚Üí 3136`  | ‚Äì          | Prep for dense layers         |\n",
    "| üî∏ FC1             | Linear(3136‚Üí128) | `3136 ‚Üí 128`         | ReLU       | Dense representation          |\n",
    "| üî∏ Dropout         | Dropout(p=0.25)  | `128 ‚Üí 128`          | ‚Äì          | Regularization against overfit|\n",
    "| üî∏ FC2             | Linear(128‚Üí10)   | `128 ‚Üí 10`           | ‚Äì          | Raw class logits (pre-Softmax)|\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Design Rationale\n",
    "\n",
    "### ‚úÖ Simplicity with Performance\n",
    "This architecture balances **simplicity**, **speed**, and **performance**, achieving **~99% accuracy** on MNIST while remaining **transparent and modifiable**.\n",
    "\n",
    "### üß© Key Design Choices\n",
    "\n",
    "- **2√ó Convolution Layers**: Enough for capturing local and mid-level features on 28√ó28 inputs.\n",
    "- **MaxPooling**: Reduces computation, introduces translational invariance.\n",
    "- **Dropout**: Prevents overfitting in dense layers, especially for small datasets.\n",
    "- **ReLU Activations**: Promote fast convergence and sparse gradients.\n",
    "- **Minimal FC layers**: Keeps parameter count low without sacrificing accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Purpose in Research\n",
    "\n",
    "This model acts as a **baseline control** for later experiments involving:\n",
    "\n",
    "- Architectural modifications (residuals, batch norm, transformers, etc.)\n",
    "- Alternative optimization strategies (SGD vs AdamW)\n",
    "- Ablation studies\n",
    "- Regularization and generalization research\n",
    "\n",
    "It serves as a **trustworthy metric anchor** to assess whether newer approaches offer real improvements or are overly complex.\n",
    "\n",
    "---\n",
    "\n",
    "## üìà Performance Baseline\n",
    "\n",
    "With standard hyperparameters:\n",
    "\n",
    "```python\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "optimizer = Adam(lr=1e-3)\n",
    "loss_fn = CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e02b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a convolutional neural network (CNN) model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the CNN model\n",
    "class MNISTNet( nn.Module ):\n",
    "    def __init__( self ):\n",
    "        \"\"\"\n",
    "        Initialize the CNN model.\n",
    "        \"\"\"\n",
    "        \n",
    "        super( ).__init__( )\n",
    "        \n",
    "        # Define the layers of the CNN:\n",
    "        self.conv1 = nn.Conv2d( 1, 32, 3, padding=1 )\n",
    "        self.conv2 = nn.Conv2d( 32, 64, 3, padding=1 )\n",
    "        self.pool = nn.MaxPool2d( 2, 2 )\n",
    "        self.fc1 = nn.Linear( 64 * 7 * 7, 128 )\n",
    "        self.dropout = nn.Dropout( 0.25 )\n",
    "        self.fc2 = nn.Linear( 128, 10 )\n",
    "\n",
    "    def forward( self, x ):\n",
    "        \"\"\"\n",
    "        Define the forward pass of the model.\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor.\n",
    "        \"\"\"\n",
    "        # Apply the convolutional layers, activation functions, and pooling:\n",
    "        # (Note: The input tensor is expected to have shape [batch_size, 1, 28, 28])\n",
    "        x = self.pool( torch.relu( self.conv1(x) ) )\n",
    "        x = self.pool( torch.relu( self.conv2(x) ) )\n",
    "        x = torch.flatten( x, 1 )\n",
    "        x = self.dropout( torch.relu( self.fc1(x) ) )\n",
    "        x = self.fc2( x )\n",
    "        return x\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
