{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0975c9f4",
   "metadata": {},
   "source": [
    "# 📘 MNIST Curve Adjustment Layers (CALs) — Experimental Baseline\n",
    "\n",
    "## 🧠 Overview\n",
    "\n",
    "In this notebook, we establish a **strong and interpretable control model** on the **MNIST handwritten digit classification task**, forming the **foundation for our exploration of Curve Adjustment Layers (CALs)** — a novel technique aimed at improving neural network convergence and generalization.\n",
    "\n",
    "CALs act as *intermediary modules* between neural layers, applying **learned deformation curves** to activations. These curves serve to *bend the output space* toward more optimal configurations, enabling the model to adaptively reshape internal representations.\n",
    "\n",
    "This notebook provides:\n",
    "- ✅ A solid CNN-based reference model\n",
    "- 📥 MNIST dataset loading and visualization\n",
    "- 🧰 Preliminaries for future CAL insertion and ablation studies\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295b8510",
   "metadata": {},
   "source": [
    "### 💽 Install any packages needed ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17b5f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea013451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd567bf",
   "metadata": {},
   "source": [
    "# Grab the MNIST Dataset:\n",
    "---\n",
    "\n",
    "The MNIST dataset is a collection of 70,000 handwritten digits (0-9) that is commonly used for training various image processing systems.\n",
    "\n",
    "\n",
    "## 📊 Dataset Summary: MNIST\n",
    "\n",
    "- **Type**: Grayscale handwritten digits  \n",
    "- **Size**: `60,000` training / `10,000` test samples  \n",
    "- **Resolution**: `28×28` pixels  \n",
    "- **Classes**: Digits `0–9`  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fb29ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST dataset downloaded to: ..\\data\n"
     ]
    }
   ],
   "source": [
    "# Download MNIST dataset to a local directory:\n",
    "# M:\\dev\\ml\\data\n",
    "\n",
    "# Create the transform function to convert the image to a tensor and normalize it:\n",
    "# (Note: The normalization values are based on the MNIST dataset statistics.)\n",
    "tx = transforms.Compose( [\n",
    "    transforms.ToTensor( ),\n",
    "    transforms.Normalize( ( 0.1307, ), ( 0.3081, ) ),\n",
    "] )\n",
    "\n",
    "data_path = os.path.join('..', 'data')\n",
    "mnist_train = datasets.MNIST( data_path, train=True, download=True, transform=tx )\n",
    "mnist_test  = datasets.MNIST( data_path, train=False, download=True, transform=tx )\n",
    "print( \"MNIST dataset downloaded to:\", data_path )\n",
    "\n",
    "count_train = len( mnist_train )\n",
    "count_test = len( mnist_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d08f8aa",
   "metadata": {},
   "source": [
    "# Examine the data:\n",
    "---\n",
    "\n",
    "Read data samples and view the image and label ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57b01dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 60000\n",
      "Number of test samples: 10000\n",
      "Image: <PIL.Image.Image image mode=L size=28x28 at 0x2752503AED0> Label: 2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print( \"Number of training samples:\", count_train )\n",
    "print( \"Number of test samples:\", count_test )\n",
    "\n",
    "# Examine data samples:\n",
    "img, label = mnist_train[ torch.randint( 0, count_train, ( ) ) ]\n",
    "print( \"Image:\", img, \"Label:\", label )\n",
    "\n",
    "# Display the first image:\n",
    "img.show( )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee88cd6",
   "metadata": {},
   "source": [
    "## 📦 Data Loader & Hyperparameter Setup\n",
    "\n",
    "To train our CNN model efficiently, we define a few key **training hyperparameters** and configure a **data preprocessing pipeline** that prepares the MNIST dataset for use in PyTorch.\n",
    "\n",
    "---\n",
    "\n",
    "### 🎛️ Training Hyperparameters\n",
    "\n",
    "| Hyperparameter   | Value      | Description                                                       |\n",
    "|------------------|------------|-------------------------------------------------------------------|\n",
    "| `batch_size`     | `64`       | Number of samples per batch — balances speed and gradient quality |\n",
    "| `epochs`         | `5`        | Total passes over the training set                               |\n",
    "| `lr`             | `0.001`    | Learning rate — controls optimizer step size                      |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "507d18e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "n_batch = 64\n",
    "epochs = 5\n",
    "lr = 0.001\n",
    "\n",
    "# Create a DataLoader to load the dataset in batches:\n",
    "data_loader = DataLoader( mnist_train,\n",
    "                          batch_size=n_batch,\n",
    "                          shuffle=True )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0624fe45",
   "metadata": {},
   "source": [
    "# 🧠 MNIST Control Model Architecture Overview\n",
    "\n",
    "## 🎯 Objective\n",
    "\n",
    "This notebook establishes a **well-performing, yet minimal and interpretable convolutional neural network (CNN)** designed to solve the **MNIST handwritten digit classification problem**. Our intent is to create a **robust \"control\" architecture** for later comparative experiments involving more advanced or experimental models. MNIST is a widely used benchmark dataset for evaluating model performance in image recognition tasks.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## 🧱 Model Architecture\n",
    "\n",
    "A lightweight yet competitive CNN inspired by classical deep learning pipelines.\n",
    "\n",
    "| Layer              | Type            | Shape In → Out      | Activation | Notes                         |\n",
    "|--------------------|------------------|----------------------|------------|-------------------------------|\n",
    "| 🔹 Input           | Image            | `1 × 28 × 28`        | –          | Grayscale digit image         |\n",
    "| 🔸 Conv1           | Conv2d(1→32, 3×3) | `28 × 28 → 28 × 28`  | ReLU       | Padding preserves resolution  |\n",
    "| 🔸 MaxPool1        | MaxPool2d(2×2)   | `28 × 28 → 14 × 14`  | –          | Downsamples feature maps      |\n",
    "| 🔸 Conv2           | Conv2d(32→64, 3×3)| `14 × 14 → 14 × 14` | ReLU       | Captures mid-level patterns   |\n",
    "| 🔸 MaxPool2        | MaxPool2d(2×2)   | `14 × 14 → 7 × 7`    | –          | Further spatial reduction     |\n",
    "| 🔸 Flatten         | –                | `64 × 7 × 7 → 3136`  | –          | Prep for dense layers         |\n",
    "| 🔸 FC1             | Linear(3136→128) | `3136 → 128`         | ReLU       | Dense representation          |\n",
    "| 🔸 Dropout         | Dropout(p=0.25)  | `128 → 128`          | –          | Regularization against overfit|\n",
    "| 🔸 FC2             | Linear(128→10)   | `128 → 10`           | –          | Raw class logits (pre-Softmax)|\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ Design Rationale\n",
    "\n",
    "### ✅ Simplicity with Performance\n",
    "This architecture balances **simplicity**, **speed**, and **performance**, achieving **~99% accuracy** on MNIST while remaining **transparent and modifiable**.\n",
    "\n",
    "### 🧩 Key Design Choices\n",
    "\n",
    "- **2× Convolution Layers**: Enough for capturing local and mid-level features on 28×28 inputs.\n",
    "- **MaxPooling**: Reduces computation, introduces translational invariance.\n",
    "- **Dropout**: Prevents overfitting in dense layers, especially for small datasets.\n",
    "- **ReLU Activations**: Promote fast convergence and sparse gradients.\n",
    "- **Minimal FC layers**: Keeps parameter count low without sacrificing accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧪 Purpose in Research\n",
    "\n",
    "This model acts as a **baseline control** for later experiments involving:\n",
    "\n",
    "- Architectural modifications (residuals, batch norm, transformers, etc.)\n",
    "- Alternative optimization strategies (SGD vs AdamW)\n",
    "- Ablation studies\n",
    "- Regularization and generalization research\n",
    "\n",
    "It serves as a **trustworthy metric anchor** to assess whether newer approaches offer real improvements or are overly complex.\n",
    "\n",
    "---\n",
    "\n",
    "## 📈 Performance Baseline\n",
    "\n",
    "With standard hyperparameters:\n",
    "\n",
    "```python\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "optimizer = Adam(lr=1e-3)\n",
    "loss_fn = CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95e02b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a convolutional neural network (CNN) model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the CNN model\n",
    "class MNISTNet( nn.Module ):\n",
    "    def __init__( self ):\n",
    "        \"\"\"\n",
    "        Initialize the CNN model.\n",
    "        \"\"\"\n",
    "        \n",
    "        super( ).__init__( )\n",
    "        \n",
    "        # Define the layers of the CNN:\n",
    "        self.conv1 = nn.Conv2d( 1, 32, 3, padding=1 )\n",
    "        self.conv2 = nn.Conv2d( 32, 64, 3, padding=1 )\n",
    "        self.pool = nn.MaxPool2d( 2, 2 )\n",
    "        self.fc1 = nn.Linear( 64 * 7 * 7, 128 )\n",
    "        self.dropout = nn.Dropout( 0.25 )\n",
    "        self.fc2 = nn.Linear( 128, 10 )\n",
    "\n",
    "    def forward( self, x ):\n",
    "        \"\"\"\n",
    "        Define the forward pass of the model.\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor.\n",
    "        \"\"\"\n",
    "        # Apply the convolutional layers, activation functions, and pooling:\n",
    "        # (Note: The input tensor is expected to have shape [batch_size, 1, 28, 28])\n",
    "        x = self.pool( torch.relu( self.conv1(x) ) )\n",
    "        x = self.pool( torch.relu( self.conv2(x) ) )\n",
    "        x = torch.flatten( x, 1 )\n",
    "        x = self.dropout( torch.relu( self.fc1(x) ) )\n",
    "        x = self.fc2( x )\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032aa666",
   "metadata": {},
   "source": [
    "## 🚂 Model Training Loop\n",
    "\n",
    "With the data loaders and architecture in place, we now define and execute the **training loop** to optimize the model parameters using backpropagation.\n",
    "\n",
    "This loop follows a typical supervised learning pattern:\n",
    "1. 🔄 Load a batch of input images and labels\n",
    "2. 🧮 Forward pass through the network\n",
    "3. 🎯 Compute the loss against ground truth\n",
    "4. 🔁 Backpropagate gradients\n",
    "5. 🛠️ Update model weights via optimizer\n",
    "\n",
    "---\n",
    "\n",
    "### ⚙️ Optimizer & Loss Function\n",
    "\n",
    "```python\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "model = MNISTNet().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bf088f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📘 Epoch 1/5 - Loss: 139.1940\n",
      "📘 Epoch 2/5 - Loss: 49.5114\n",
      "📘 Epoch 3/5 - Loss: 36.0982\n",
      "📘 Epoch 4/5 - Loss: 27.2234\n",
      "📘 Epoch 5/5 - Loss: 22.1077\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the model and use the GPU if available:\n",
    "device = torch.device( \"cuda\" if torch.cuda.is_available() else \"cpu\" )\n",
    "model  = MNISTNet( ).to( device )\n",
    "\n",
    "# Define loss function and optimizer:\n",
    "loss_fn   = nn.CrossEntropyLoss( )\n",
    "optimizer = optim.Adam( model.parameters( ), lr=lr )\n",
    "\n",
    "# Training the model:\n",
    "for epoch in range( epochs ):\n",
    "    model.train( )  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in data_loader:\n",
    "        images, labels = images.to( device ), labels.to( device )\n",
    "\n",
    "        # Zero gradients from previous step\n",
    "        optimizer.zero_grad( )\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model( images )\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn( outputs, labels )\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward( )\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step( )\n",
    "\n",
    "        # Accumulate loss\n",
    "        running_loss += loss.item( )\n",
    "\n",
    "    print( f\"📘 Epoch {epoch+1}/{epochs} - Loss: {running_loss:.4f}\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4dcd8b",
   "metadata": {},
   "source": [
    "# 📁 Saving the model ...\n",
    "\n",
    "## ✅ Recommended: Save Model Weights (State Dict)\n",
    "> This is the standard, flexible approach for reloading models in code.\n",
    "\n",
    "### 🔐 Save:\n",
    "```python\n",
    "torch.save( model.state_dict(), \"mnist_cnn.pth\" )\n",
    "```\n",
    "\n",
    "### 🔁 Load:\n",
    "```python\n",
    "model = MNISTNet( ).to( device )\n",
    "model.load_state_dict( torch.load(\"mnist_cnn.pth\") )\n",
    "model.eval( ) # Important for inference mode (dropout, etc.)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🧱 Alternative: Save Full Model (Not Recommended Long-Term)\n",
    "```python\n",
    "torch.save( model, \"mnist_full_model.pth\" )\n",
    "```\n",
    "\n",
    "And to load:\n",
    "```python\n",
    "model = torch.load(\"mnist_full_model.pth\")\n",
    "model.eval()\n",
    "```\n",
    "\n",
    "### ⚠️ Caution: This approach serializes the full model structure and class. It:\n",
    "- Breaks if the source code changes\n",
    "- Isn’t portable across versions or environments\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b20ba70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: ..\\models\\mnist_cnn.pth\n"
     ]
    }
   ],
   "source": [
    "filename = 'mnist_cnn.pth'\n",
    "model_output_dir = os.path.join( '..', 'models' )\n",
    "model_output_path = os.path.join( model_output_dir, filename )\n",
    "\n",
    "if not os.path.exists( model_output_dir ):\n",
    "    os.makedirs( model_output_dir )\n",
    "    \n",
    "# Save the trained model\n",
    "torch.save( model.state_dict( ), model_output_path )\n",
    "print( \"Model saved to:\", model_output_path )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fe4570",
   "metadata": {},
   "source": [
    "# 🧪 Quick Check: Inference After Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865bcbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model if not already loaded\n",
    "filename = 'mnist_cnn.pth'\n",
    "model_output_dir = os.path.join( '..', 'models' )\n",
    "load_path = os.path.join( model_output_dir, filename )\n",
    "\n",
    "model = MNISTNet( ).to( device )\n",
    "model.load_state_dict( torch.load( load_path ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee54ec53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 2, Ground Truth: 2\n"
     ]
    }
   ],
   "source": [
    "# Test the model on a single image\n",
    "model.eval( )\n",
    "with torch.no_grad( ):\n",
    "    # Load a test image:\n",
    "    image, label = mnist_test[ 990 ]\n",
    "    image = tx( image ).unsqueeze( 0 ).to( device )\n",
    "\n",
    "    # Make prediction:\n",
    "    output = model( image )\n",
    "    pred = output.argmax( dim=1 ).item( )\n",
    "    print( f\"Predicted: {pred}, Ground Truth: {label}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d36d6ab",
   "metadata": {},
   "source": [
    "## 📊 Evaluation Loop & Accuracy Visualization\n",
    "\n",
    "Once the model is trained, we run an evaluation pass over the test set to:\n",
    "- Compute total accuracy\n",
    "- Track predictions across all batches\n",
    "- Plot a performance summary graph\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2a1726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Test Accuracy: 98.93%\n",
      "Total Images: 10000, Correct Predictions: 9893\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Rebuild test dataset with transform applied\n",
    "mnist_test = datasets.MNIST( data_path, train=False, download=True, transform=tx )\n",
    "\n",
    "# Create test DataLoader\n",
    "test_loader = DataLoader( mnist_test, batch_size=64, shuffle=False )\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval( )\n",
    "\n",
    "total   = 0\n",
    "correct = 0\n",
    "losses        = [ ]\n",
    "predictions   = [ ]\n",
    "ground_truths = [ ]\n",
    "\n",
    "with torch.no_grad( ):\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to( device ), labels.to( device )\n",
    "\n",
    "        outputs = model( images )\n",
    "        loss = loss_fn( outputs, labels )\n",
    "        losses.append( loss.item() )\n",
    "\n",
    "        _, predicted = torch.max( outputs.data, 1 )\n",
    "        predictions.extend( predicted.cpu().numpy() )\n",
    "        ground_truths.extend( labels.cpu().numpy() )\n",
    "\n",
    "        correct += (predicted == labels).sum( ).item( )\n",
    "        total += labels.size( 0 )\n",
    "\n",
    "accuracy = 100.0 * correct / total\n",
    "print( f\"✅ Test Accuracy: {accuracy:.2f}%\")\n",
    "print( f\"Total Images: {total}, Correct Predictions: {correct}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103e0ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
